# Course: Generative AI for Software Engineering (GenAI4SE) 
<figure>
  <img src="assets/copilot.jpeg" alt="genai4se"/>
  <figcaption>Copilot</figcaption>
  <a href="https://practical365.com/microsoft-365-copilot-costs">(Image Source)</a>
</figure>

## Objective of Workshop
Software engineering in the large is an effort-intensive and time-consuming activity whereas IT systems today need to make changes in the shortest possible duration. Most complex, large-scale software systems of today derive their requirements from existing (legacy) software and partial (incomplete) descriptions. Software development is thus a complex combination of transformation, reverse and forward engineering, involving code, data, and specifications, wherein data is both structured and unstructured. Expertise from subject matter experts (SMEs) is essential at each phase, which brings in the important component of domain knowledge. While Model-Driven Engineering (MDE), Knowledge Engineering (KE), and Reverse Engineering (RE) have mitigated some of the challenges, the emergence of Generative AI techniques holds the potential for a substantial breakthrough, though is yet to bring a consistent and substantial jump in productivity. There are challenges in understanding and resolving issues reported in GitHub. The absence of high-quality datasets that encompass a wide range of programming tasks, styles, and languages add to the challenges. With dynamically changing businesses of enterprises, and evolution of fast-changing and new technologies, the LLMs need to keep pace with the evolving code knowledge.

Use of GenAI for software development has seen increasing maturity in the past 1+ year. Different tools like GitHub Copilot, Amazon Q developer agent (Code Whisperer), AutoCodeRover + GPT 4o, Assistant GRU, SWE agent + Claude 3.5 Sonnet have enhanced and are enhancing code development, code completion, test case generation, debugging and issue fixing tasks. Some methods have exploited the instruction tuning and reinforcement learning with feedback. Several more small and large models and tools are exploiting RACG techniques and claim to considerably enhance the software development tasks.

The new paradigm of LLM Based AI agents, have demonstrated effectiveness in variety of Software Engineering (SE) tasks, such as program generation, software testing and debugging and program improvement as well as end-to-end software engineering. These agents can extend the capabilities of the backbone LLMs by utilizing external resources and tools and soliciting human interactions. From SE perspective, there is a need to analyze how LLM-based agents can tackle different software development and maintenance tasks. Whereas, from the agent perspective, there is a need to throw some light on the basic agentic design components, including planning, memory, perception, action and their roles and collaboration mechanisms, in multi-agent settings.

The proposed workshop aims to provide a collaborative platform for researchers and practitioners to delve into the convergence of traditional MDE, KE, and RE methodologies together with Generative AI technologies. By synergizing the strengths of Gen AI, LLM Agentic Frameworks, modeling, and knowledge representation for SDLC, our goal is to define a trajectory toward enhanced software engineering practices. We seek discussion on the following pivotal questions:

Architecting, designing, developing and maintaining industry-strength software is a multi-skill, long-drawn activity that cannot be effectively addressed by LLMs alone. What kinds of augmentation make it effective?
LLM is a vast storehouse of general information, but the typical need during SDLC is rather sharply focused. How best to bear local knowledge at scale to get the required focus?
How can Generative AI be effectively utilized for mining and constructing purpose-driven knowledge from software artifacts? Can Generative AI catalyze existing legacy modernization techniques to reduce cost, time and improve correctness?
How can Generative AI enhance the synthesis of tests and test data during SDLC?
Can bug fixes and change requests be analyzed and implemented expeditiously using Generative AI?
What are the best practices for maintaining the accuracy, relevance and reliability of Generative AI generated software artifacts?
What are the state-of-the-art techniques, experimental models, methodologies, benchmark datasets and evaluation metrics employed for the usage of LLMs and LLM-based agents in SE applications? What are the key differences in task performance between LLMs and LLM-based agents?
## Call For Abstract And Call For Paper
Software Engineering (SE) in the large is an effort-intensive and time-consuming activity whereas IT systems today need to make changes in the shortest possible duration. Software development is thus a complex combination of transformation, reverse and forward engineering, involving code, data, and specifications. While Model-Driven Engineering (MDE), Knowledge Engineering (KE), and Reverse Engineering (RE) have mitigated some of the challenges, the emergence of Generative AI techniques holds the potential for a substantial breakthrough and is an important area of study and exploration. The absence of high-quality datasets that encompass a wide range of programming tasks, styles, and languages add to the challenges. Further, as the technology and business landscapes change, LLMs constantly need to match the pace.

The new paradigm of LLM Based AI agents have demonstrated effectiveness in variety of Software Engineering (SE) tasks, such as program generation, software testing and debugging and program improvement as well as end-to-end software engineering. These agents can extend the capabilities of the backbone LLMs by utilizing external resources and tools and soliciting human interactions.   From SE perspective, there is a need to analyze how LLM-based agents can tackle tasks across Software Development Lifecycle (SDLC) and how to design the basic agentic components, including planning, memory, perception, action and their roles and collaboration mechanisms, in multi-agent settings.

The Workshop on GenAI Based Software Engineering aims to provide a collaborative platform for researchers from academia industry, and practitioners to delve into the convergence of traditional MDE, KE, and RE methodologies and software engineering approaches together with Generative AI technologies. We solicit submissions in the form of one-page abstract (max 500 words) OR papers of maximum 5-pages + 1-page references in the standard ACM format describing case studies, interesting experiments, techniques and best practices, and lessons learned while applying Generative AI and LLM agent frameworks to various SE areas, but not limited to the following topics:

Agentic frameworks for SE
Intelligent Code Assistants
Neuro-Symbolic Approaches for SE
GenAI Frameworks for SE with Human in the Loop
Advanced Retrieval Augmentation for SE
Datasets for SE
LLMs for Knowledge Engineering
Tuning of SLMs (Small Language Models) for SE
Technical Risks associated in AI/ML implementations
Negative Results demonstrating failed application of GenAI for SE
Low-cost GenAI solutions for SE
Reliability of GenAI generated software artifacts
LLMs as a judge for evaluation of SE tasks

The areas of interest across SE include but are not restricted to Requirements Engineering, Software Architecture and Design, Software Development and Maintenance, Software Verification, Testing and Debugging, Legacy Modernization, Reverse Engineering from code, documents, Software Analysis, Repository level coding tasks including code development , code completion, test case generation, debugging and issue fixing tasks.

## Submission Information
Abstract (maximum 500 words) OR papers (maximum 5 pages + 1 page references). Abstracts can be from already published work at other conference venues and should include the details of when and where the original work is published. Papers should be original work, not being considered for publishing elsewhere, written in text format, in English. Accepted papers may be considered for publication at an appropriate forum (either in ACM DL, or SE Notes or CEUR publication). Abstracts should be submitted via the Google Form Link: Click Here!. Papers should be submitted via Easychair link: Submit Here. 

### Acceptance criteria : 
Abstracts and papers will be selected for presentation based on reviews by members of the workshop organizing committee. The tentative criteria will be the clarity of articulation of the problem being solved, motivating the need of Generative AI to solve the problem and the novelty of the approach. Authors of accepted papers will receive further instructions for submitting camera-ready versions.

## Program Details
Not Available

## Contact Information
In case of any questions, you can write an email to genai4se@googlegroups.com
